"""
Jupyter Notebook for Multi-Agent Translation Analysis
Complete statistical analysis and visualization of experiment results
"""

# %% [markdown]
# # üìä Multi-Agent Translation Analysis
# 
# **Project**: Multi-Agent Translation System (HW3)  
# **Author**: Roie Gilad  
# **Date**: November 19, 2025
# 
# ## Overview
# 
# This notebook analyzes the impact of spelling errors on semantic preservation through a 3-stage translation chain:
# - **Agent 1**: English ‚Üí French
# - **Agent 2**: French ‚Üí Hebrew  
# - **Agent 3**: Hebrew ‚Üí English
# 
# We measure semantic drift using cosine distance between original and final English text.

# %% [markdown]
# ## 1. Setup and Data Loading

# %%
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Set style
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Load experiment results
with open('../results/experiment.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

df = pd.DataFrame(data)
print(f"‚úì Loaded {len(df)} experiment results")
print(f"‚úì Error rates tested: {sorted(df['error_rate'].unique())}")
print(f"‚úì Number of sentences: {df['sentence_id'].nunique()}")
print(f"‚úì Runs per configuration: {df['run'].nunique()}")

# %% [markdown]
# ## 2. Descriptive Statistics

# %%
# Summary statistics
summary = df.groupby('error_rate')['distance'].agg([
    ('mean', 'mean'),
    ('std', 'std'),
    ('min', 'min'),
    ('max', 'max'),
    ('median', 'median')
]).reset_index()

summary['error_rate_pct'] = summary['error_rate'] * 100
print("\nüìä Summary Statistics by Error Rate:\n")
print(summary.to_string(index=False))

# %% [markdown]
# ## 3. Statistical Analysis
# 
# ### 3.1 Correlation Analysis
# 
# We test the hypothesis that error rate is correlated with semantic distance.

# %%
# Pearson correlation
pearson_r, pearson_p = stats.pearsonr(df['error_rate'], df['distance'])
print(f"Pearson correlation: r = {pearson_r:.4f}, p = {pearson_p:.2e}")

# Spearman correlation (non-parametric)
spearman_r, spearman_p = stats.spearmanr(df['error_rate'], df['distance'])
print(f"Spearman correlation: œÅ = {spearman_r:.4f}, p = {spearman_p:.2e}")

if pearson_p < 0.001:
    print("‚úì Strong statistical significance (p < 0.001)")
    print("‚úì Error rate strongly correlates with semantic drift")

# %% [markdown]
# ### 3.2 ANOVA Test
# 
# We test if different error rates produce significantly different semantic distances.

# %%
# Group data by error rate
groups = [group['distance'].values for name, group in df.groupby('error_rate')]

# One-way ANOVA
f_stat, anova_p = stats.f_oneway(*groups)
print(f"\nANOVA F-statistic: {f_stat:.4f}, p = {anova_p:.2e}")

if anova_p < 0.001:
    print("‚úì Error rates produce significantly different semantic distances")

# %% [markdown]
# ### 3.3 Linear Regression
# 
# We model the relationship: $\text{Distance} = \beta_0 + \beta_1 \times \text{Error Rate} + \epsilon$

# %%
from scipy.stats import linregress

slope, intercept, r_value, p_value, std_err = linregress(
    df['error_rate'], 
    df['distance']
)

print(f"\nüìà Linear Regression Model:")
print(f"   Distance = {intercept:.4f} + {slope:.4f} √ó Error_Rate")
print(f"   R¬≤ = {r_value**2:.4f}")
print(f"   p-value = {p_value:.2e}")
print(f"   Standard error = {std_err:.4f}")

# Interpretation
print(f"\nüí° Interpretation:")
print(f"   - For each 10% increase in error rate,")
print(f"     semantic distance increases by {slope*0.1:.4f} units")
print(f"   - Model explains {r_value**2*100:.1f}% of variance")

# %% [markdown]
# ## 4. Visualization

# %% [markdown]
# ### 4.1 Main Results: Error Rate vs Semantic Distance

# %%
fig, ax = plt.subplots(figsize=(12, 7))

# Plot each sentence separately
colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
for i, sid in enumerate(sorted(df['sentence_id'].unique())):
    subset = df[df['sentence_id'] == sid]
    
    # Group by error rate
    grouped = subset.groupby('error_rate')['distance'].agg(['mean', 'std']).reset_index()
    grouped['error_rate_pct'] = grouped['error_rate'] * 100
    
    ax.plot(
        grouped['error_rate_pct'],
        grouped['mean'],
        marker='o',
        label=f'Sentence {sid + 1}',
        linewidth=2.5,
        markersize=8,
        color=colors[i]
    )
    
    # Error bars
    ax.fill_between(
        grouped['error_rate_pct'],
        grouped['mean'] - grouped['std'],
        grouped['mean'] + grouped['std'],
        alpha=0.2,
        color=colors[i]
    )

ax.set_xlabel('Spelling Error Rate (%)', fontsize=13, fontweight='bold')
ax.set_ylabel('Cosine Distance (Semantic Drift)', fontsize=13, fontweight='bold')
ax.set_title('Impact of Spelling Errors on Semantic Preservation\nthrough 3-Stage Translation Chain', 
             fontsize=14, fontweight='bold', pad=20)
ax.legend(fontsize=11, loc='upper left')
ax.grid(True, alpha=0.3, linestyle='--')

plt.tight_layout()
plt.savefig('../results/error_impact_detailed.png', dpi=300, bbox_inches='tight')
plt.show()

print("‚úì Saved: results/error_impact_detailed.png")

# %% [markdown]
# ### 4.2 Distribution Analysis

# %%
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
error_rates = sorted(df['error_rate'].unique())

for idx, er in enumerate(error_rates):
    ax = axes[idx // 3, idx % 3]
    subset = df[df['error_rate'] == er]['distance']
    
    ax.hist(subset, bins=15, edgecolor='black', alpha=0.7)
    ax.axvline(subset.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {subset.mean():.3f}')
    ax.set_title(f'Error Rate: {er*100:.0f}%', fontweight='bold')
    ax.set_xlabel('Semantic Distance')
    ax.set_ylabel('Frequency')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('../results/distance_distributions.png', dpi=300, bbox_inches='tight')
plt.show()

print("‚úì Saved: results/distance_distributions.png")

# %% [markdown]
# ### 4.3 Box Plot Comparison

# %%
fig, ax = plt.subplots(figsize=(12, 7))

df['error_rate_pct'] = df['error_rate'] * 100
sns.boxplot(
    data=df,
    x='error_rate_pct',
    y='distance',
    palette='Set2',
    ax=ax
)

ax.set_xlabel('Spelling Error Rate (%)', fontsize=13, fontweight='bold')
ax.set_ylabel('Cosine Distance', fontsize=13, fontweight='bold')
ax.set_title('Distribution of Semantic Distance by Error Rate', fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('../results/distance_boxplot.png', dpi=300, bbox_inches='tight')
plt.show()

print("‚úì Saved: results/distance_boxplot.png")

# %% [markdown]
# ## 5. Example Translations

# %%
print("\nüìù Example Translation Chains:\n")

for sid in df['sentence_id'].unique():
    print(f"\n{'='*80}")
    print(f"SENTENCE {sid + 1}")
    print(f"{'='*80}")
    
    # Get examples at 0%, 25%, and 50% error rates
    for er in [0.0, 0.25, 0.5]:
        example = df[(df['sentence_id'] == sid) & (df['error_rate'] == er)].iloc[0]
        
        print(f"\nüî∏ Error Rate: {er*100:.0f}%")
        print(f"   Original:  {example['original'][:80]}...")
        print(f"   Corrupted: {example['corrupted'][:80]}...")
        print(f"   Final:     {example['final'][:80]}...")
        print(f"   Distance:  {example['distance']:.4f}")

# %% [markdown]
# ## 6. Key Findings
# 
# ### Statistical Summary
# 
# 1. **Strong Correlation**: 
#    - Pearson r = {:.4f} (p < 0.001)
#    - Clear positive relationship between error rate and semantic drift
# 
# 2. **Linear Relationship**:
#    - R¬≤ = {:.4f}
#    - Model: Distance = {:.4f} + {:.4f} √ó Error_Rate
#    - Every 10% error increase ‚Üí +{:.4f} distance units
# 
# 3. **Statistical Significance**:
#    - ANOVA F = {:.4f} (p < 0.001)
#    - Different error rates produce significantly different results
# 
# ### Practical Implications
# 
# - **Baseline (0% errors)**: Distance ‚âà {:.4f}
# - **Moderate errors (25%)**: Distance ‚âà {:.4f}
# - **High errors (50%)**: Distance ‚âà {:.4f}
# 
# ### Conclusion
# 
# Spelling errors significantly degrade semantic preservation through multi-stage translation.
# The relationship is linear and statistically robust, with R¬≤ = {:.4f}.

# Format with actual values
findings_text = f"""
## 6. Key Findings

### Statistical Summary

1. **Strong Correlation**: 
   - Pearson r = {pearson_r:.4f} (p < 0.001)
   - Clear positive relationship between error rate and semantic drift

2. **Linear Relationship**:
   - R¬≤ = {r_value**2:.4f}
   - Model: Distance = {intercept:.4f} + {slope:.4f} √ó Error_Rate
   - Every 10% error increase ‚Üí +{slope*0.1:.4f} distance units

3. **Statistical Significance**:
   - ANOVA F = {f_stat:.4f} (p < 0.001)
   - Different error rates produce significantly different results

### Practical Implications

- **Baseline (0% errors)**: Distance ‚âà {df[df['error_rate']==0.0]['distance'].mean():.4f}
- **Moderate errors (25%)**: Distance ‚âà {df[df['error_rate']==0.25]['distance'].mean():.4f} (+{(df[df['error_rate']==0.25]['distance'].mean() - df[df['error_rate']==0.0]['distance'].mean()):.4f})
- **High errors (50%)**: Distance ‚âà {df[df['error_rate']==0.5]['distance'].mean():.4f} (+{(df[df['error_rate']==0.5]['distance'].mean() - df[df['error_rate']==0.0]['distance'].mean()):.4f})

### Conclusion

Spelling errors significantly degrade semantic preservation through multi-stage translation.
The relationship is linear and statistically robust, with R¬≤ = {r_value**2:.4f}.
"""

print(findings_text)

# %% [markdown]
# ## 7. References
# 
# 1. Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. *arXiv preprint arXiv:1908.10084*.
# 
# 2. Cosine similarity for semantic distance measurement in NLP applications.
# 
# 3. Multi-agent orchestration with Ollama (llama3.2:3b model).

# %%
print("\n‚úÖ Analysis complete!")
print(f"üìä Generated {3} visualizations")
print(f"üìà Statistical tests performed: {3}")
print(f"üéØ Key metric: R¬≤ = {r_value**2:.4f}")
